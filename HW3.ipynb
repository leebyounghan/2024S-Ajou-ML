{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leebyounghan/2024S-Ajou-ML/blob/main/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpGhlR_biT8D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3vK_f10tKm9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_random_seed(seed_value):\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    random.seed(seed_value)\n",
        "\n",
        "# Set a random seed value\n",
        "seed_value = 42\n",
        "set_random_seed(seed_value)\n"
      ],
      "metadata": {
        "id": "fkKPwP1tGouS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_On2z4EpoSxF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqMzkz5B78J6"
      },
      "source": [
        "# pytorch 기초\n",
        "\n",
        "pytorch의 장점은 backword를 자체적으로 수행할 수 있다는 것입니다.\n",
        "\n",
        "아래의 코드는 2차원 데이터로 2차원의 weight와 1개의 bias 계산하는 예제입니다.\n",
        "\n",
        "- (requires_grad=True) 가 설정된 tensor들은 자동으로 gradiant를 계산하고 저장합니다.\n",
        "\n",
        "- loss_function을 통해 구해진 값에 대하여 .backword()를 수행하면 gradiant를 계산하게 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1e2AozKgQPa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "X = torch.tensor([[1, 2], [2, 3], [3, 4], [4, 5]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "# Initialize weights and bias with requires_grad=True\n",
        "w = torch.tensor([[0.0], [0.0]], dtype=torch.float32,requires_grad=True)\n",
        "b = torch.tensor([0.0], dtype=torch.float32, requires_grad=True)\n",
        "def forward(X):\n",
        "    return torch.matmul(X, w) + b\n",
        "\n",
        "def loss(Y, Y_pred):\n",
        "    return ((Y_pred - Y) ** 2).mean()\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    Y_pred = forward(X)\n",
        "    l = loss(Y, Y_pred)\n",
        "\n",
        "    # gradiant 초기화\n",
        "    w.grad = None\n",
        "    b.grad = None\n",
        "\n",
        "    # backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # weights와 bias 업데이트\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}, Loss: {l.item()}')\n",
        "\n",
        "print(\"Trained weights:\", w)\n",
        "print(\"Trained bias:\", b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD7J3k7HD1UW"
      },
      "source": [
        "아래의 예시는 위와 동일한 코드이지만, 편하게 사용할 수 있는 함수들입니다.\n",
        "\n",
        "- 각 대응되는 부분들을 확인해보세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8Lru1wmIRrm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hunQe9su4sk"
      },
      "outputs": [],
      "source": [
        "# Define the data\n",
        "X = torch.tensor([[1, 2], [2, 3], [3, 4], [4, 5]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "initial_weight = torch.tensor([[0.0, 0.0]], dtype=torch.float32)\n",
        "initial_bias = torch.tensor([0.0], dtype=torch.float32)\n",
        "\n",
        "\n",
        "LinearModel = nn.Linear(in_features=2, out_features=1, bias=True)  # linear layer\n",
        "LinearModel.weight.data = initial_weight.clone() #동일한 결과를 위해 동일하게 초기화\n",
        "LinearModel.bias.data = initial_bias.clone() #동일한 결과를 위해 동일하게 초기화\n",
        "\n",
        "\n",
        "criterion = nn.MSELoss() # loss fucntion 정의\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(LinearModel.parameters(), lr=0.01) # optimizer 정의\n",
        "\n",
        "# Training loop\n",
        "n_iters = 100\n",
        "for epoch in range(n_iters):\n",
        "\n",
        "    Y_pred = LinearModel(X)\n",
        "\n",
        "\n",
        "    loss = criterion(Y_pred, Y)\n",
        "\n",
        "    optimizer.zero_grad() # gradiant 초기화\n",
        "    loss.backward() # backword process\n",
        "    optimizer.step() # weight (&bias) update\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "trained_weight, trained_bias = LinearModel.weight.data, LinearModel.bias.data\n",
        "print(\"Trained weights:\", trained_weight)\n",
        "print(\"Trained bias:\", trained_bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHBvqahvwW0_"
      },
      "source": [
        "#### GPU 사용\n",
        "\n",
        "- 런타임 > 런타임 유형변경 > GPU 선택\n",
        "- .to() method를 사용하여 GPU로 모델과 데이터를 올릴 수 있음\n",
        "- .cuda() 를 사용하는 것도 가능\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPbBLZKYwZOX"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "LinearModel.to(device) # GPU로 올리기\n",
        "print(LinearModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIrGskG6wlOI"
      },
      "outputs": [],
      "source": [
        "X = X.to(device) # data도 GPU로 올려야 연산 가능함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9chX5rowrMy"
      },
      "outputs": [],
      "source": [
        "LinearModel(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omHWncM6wx92"
      },
      "outputs": [],
      "source": [
        "LinearModel.cpu() # 다시 CPU로\n",
        "X.cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWPx3y8eTk47"
      },
      "source": [
        "# 문제 1\n",
        "\n",
        "\n",
        "- MNIST Dataset을 활용하여 손글씨 이미지(숫자)를 예측하는 모델을 만드세요.\n",
        "- 해당 데이터는 0~9까지의 숫자를 가지고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbsm-yiFtKnD"
      },
      "outputs": [],
      "source": [
        "# Load training data\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncBsv-WqtKnD"
      },
      "source": [
        "MNIST 데이터를 데이터 로더에 넣어서 사용하면 미니 배치 단위로 꺼내 쓸 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVA-3mo7tKnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978cf41c-2ef2-428d-a5a2-e221b8b31aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
          ]
        }
      ],
      "source": [
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True, # training data\n",
        "    download=True,\n",
        "    transform=v2.ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "val_size = 5000\n",
        "train_size = len(training_data) - val_size\n",
        "training_data, val_data = random_split(training_data, [train_size, val_size])\n",
        "\n",
        "# Load test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # test data\n",
        "    download=True,\n",
        "    transform=v2.ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# data loader\n",
        "# train, test 각각의 data loader 생성\n",
        "smaple_loader = torch.utils.data.DataLoader(training_data, batch_size=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdM1S6wItKnD"
      },
      "outputs": [],
      "source": [
        "# train feature와 label을 train_loader로부터 가져오기\n",
        "sample_features, sample_labels = next(iter(smaple_loader))\n",
        "print(f\"Feature batch shape: {sample_features.size()}\")\n",
        "print(f\"Labels batch shape: {sample_labels.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDuCXBkrtKnE"
      },
      "source": [
        "#### 이미지로 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhg7bSA6tKnE"
      },
      "outputs": [],
      "source": [
        "img = sample_features[0].squeeze()\n",
        "label = sample_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM9VU071tKnE"
      },
      "source": [
        "## 문제 1-1\n",
        "\n",
        "MNIST 데이터셋을 아래의 조건에 따라 학습시키세요.\n",
        "\n",
        "Fully connected layer (multi layer perceptron)로 NeuralNetwork를 아래의 조건에 맞게 완성하세요.\n",
        "\n",
        " - NeuralNetwork 모델 구축\n",
        "    - 3개의 linear layer와 2개의 ReLU layer를 사용하세요.\n",
        "    - nn.Linear, nn.ReLU\n",
        "    - 각 layer의 hidden dimension size는 자유롭게 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRv79hjNtKnE"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten() # 28x28 이미지를 784 픽셀 값의 배열로 변경\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            # 3개의 linear layer와 2개의 ReLU layer를 구성하세요\n",
        "        #===================================================#\n",
        "\n",
        "\n",
        "\n",
        "        #===================================================#\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # forward 함수 구현\n",
        "        #===================================================#\n",
        "\n",
        "\n",
        "\n",
        "        #===================================================#\n",
        "        return logits # forward 결과 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msics0potKnE"
      },
      "source": [
        "## 문제 1-2\n",
        "\n",
        "위에서 만든 NeuralNetwork 모델을 학습시키세요.\n",
        "train과 test함수를 만들세요.\n",
        "\n",
        "- CrossEntropy 사용 (nn.CrossEntropyLoss)\n",
        "- Epoch : 10, batch size : 32\n",
        "- validation 정확도 90% 이상"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJyNdByetKnE"
      },
      "outputs": [],
      "source": [
        "# hyperparameter 설정\n",
        "import torch.optim as optim\n",
        "FcModel = NeuralNetwork()\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.SGD(FcModel.parameters(), lr=0.001, momentum=0.9) # optimizer\n",
        "\n",
        "EPOCHS = 10 # the number of epochs\n",
        "n_batch = 32 # the number of batches\n",
        "\n",
        "# data loader의 batch size을 16로 변경\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=n_batch, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=n_batch, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=n_batch, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMXq6SeztKnE"
      },
      "outputs": [],
      "source": [
        "def train(dataloader , model , loss_fn , optimizer , lr_scheduler=None):\n",
        "    size = 0\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss , epoch_correct = 0 , 0\n",
        "\n",
        "    for i ,(data_ , target_) in enumerate(dataloader):\n",
        "\n",
        "        #===================================================#\n",
        "\n",
        "\n",
        "\n",
        "        #===================================================#\n",
        "\n",
        "    if lr_scheduler != None:\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    return epoch_correct/size , epoch_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUowJRy2tKnF"
      },
      "outputs": [],
      "source": [
        "def test(dataloader , model , loss_fn):\n",
        "    size = 0\n",
        "    num_baches = len(dataloader)\n",
        "    epoch_loss , epoch_correct= 0 ,0\n",
        "    with torch.no_grad(): # grad 연산 X\n",
        "        model.eval() # evaluation dropout 연산시\n",
        "        for i, (data_ , target_) in enumerate(dataloader):\n",
        "\n",
        "            #========================================#\n",
        "\n",
        "\n",
        "\n",
        "            #========================================#\n",
        "\n",
        "    return epoch_correct/size  , epoch_loss / num_baches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDGlOiQptKnF"
      },
      "outputs": [],
      "source": [
        "FcModel.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmqvpBf-tKnF"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train_acc , train_loss = train(train_loader ,\n",
        "                                   FcModel ,\n",
        "                                   criterion ,\n",
        "                                   optimizer )\n",
        "\n",
        "    val_acc , val_loss = test(val_loader , FcModel , criterion)\n",
        "    print(f'epoch:{epoch} \\\n",
        "    train_loss = {train_loss:.4f} , train_acc:{train_acc:.4f} \\\n",
        "    val_loss = {val_loss:.4f} , val_acc:{val_acc:.4f} \\\n",
        "    learning rate: {optimizer.param_groups[0][\"lr\"]}')\n",
        "\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        counter = 0\n",
        "        best_loss = val_loss\n",
        "        torch.save(FcModel.state_dict() , \"checkpoints/NN_best.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3s0MZbmg_OC"
      },
      "source": [
        "# 문제 1-3 : CNN\n",
        "\n",
        "- CNN 모델을 아래의 조건과 같이 구축하여 학습하시오.\n",
        "- validation 정확도 90% 이상"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS2uNIuO1jxF"
      },
      "source": [
        "아래의 조건을 만족하는 CNN model을 만드시오.\n",
        "\n",
        "\n",
        " - CNN layer 1 - filter 수 32, filter size : 3,\n",
        " - Max pooling : 2 x 2\n",
        " - CNN layer 2 - filter 수 64, filter size : 3,\n",
        " - Max pooling : 2 x 2\n",
        " - CNN layer 3 - filter 수 128, filter size : 3,\n",
        " - Max pooling : 2 x 2\n",
        " - Fc layer 1 : last Cnn feature size (flatten) -> 128\n",
        " - ReLU ()\n",
        " - Fc layer 2 : 128 -> 64\n",
        " - ReLU ()\n",
        " - Fc layer 3 : 64 -> 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNTGtF-pjnoy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        #===============================================#\n",
        "\n",
        "\n",
        "\n",
        "        #===============================================#\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #===============================================#\n",
        "\n",
        "\n",
        "\n",
        "        #===============================================#\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRyVxEOQtKnG"
      },
      "outputs": [],
      "source": [
        "# hyperparameter 설정\n",
        "import torch.optim as optim\n",
        "SimModel = SimpleCNN()\n",
        "SimModel.to(device)\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.SGD(SimModel.parameters(), lr=0.001, momentum=0.9) # optimizer\n",
        "\n",
        "EPOCHS = 10 # the number of epochs\n",
        "n_batch = 32 # the number of batches\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=n_batch, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=n_batch, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=n_batch, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wcUGfuJtKnG"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train_acc , train_loss = train(train_loader ,\n",
        "                                   SimModel ,\n",
        "                                   criterion ,\n",
        "                                   optimizer )\n",
        "\n",
        "    val_acc , val_loss = test(val_loader , SimModel , criterion)\n",
        "    print(f'epoch:{epoch} \\\n",
        "    train_loss = {train_loss:.4f} , train_acc:{train_acc:.4f} \\\n",
        "    val_loss = {val_loss:.4f} , val_acc:{val_acc:.4f} \\\n",
        "    learning rate: {optimizer.param_groups[0][\"lr\"]}')\n",
        "\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        counter = 0\n",
        "        best_loss = val_loss\n",
        "        torch.save(FcModel.state_dict() , \"checkpoints/Simple_CNN_best.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDS5ESiltKnG"
      },
      "source": [
        "# Smoke image dataset\n",
        "\n",
        "\n",
        "- 본 데이터셋은 흡연자의 모습과 비흡자의 모습이 담긴 이미지 파일입니다.\n",
        "- 이미지 파일을 python으로 가져오기 위해서 다음 과정을 수행합니다.\n",
        "\n",
        "\n",
        "\n",
        "1.   이미지가 있는 file path를 pandas DataFrame에 label과 함께 저장\n",
        "2.   데이터 로드를 효율적으로 하기 위해서, 학습 배치마다 해당 path의 이미지를 불러옴\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY9b3CIHtKnG"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeOXAn8ytKnG"
      },
      "outputs": [],
      "source": [
        "data_path = \"/home/qudgks/workspace/smoke\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DfnUJs2tKnG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "def create_dataframe(data_path, label_list, data_type):\n",
        "    df = pd.DataFrame({\"path\": [], \"label\": [], \"class_id\": []})\n",
        "    img_list = glob(os.path.join(data_path, '*.jpg'))\n",
        "\n",
        "    for img in img_list:\n",
        "        file_name = os.path.splitext(img)[0].split(\"/\")[-1]\n",
        "        if file_name[0:len(label_list[0])] == label_list[0]:\n",
        "            new_data =pd.DataFrame({\"path\":img,\"label\":label_list[0], \"class_id\":0}, index=[1])\n",
        "            df = pd.concat([df, new_data], ignore_index=True)\n",
        "        elif file_name[0:len(label_list[1])] == label_list[1]:\n",
        "            new_data =pd.DataFrame({\"path\":img,\"label\":label_list[1], \"class_id\":1}, index=[1])\n",
        "            df = pd.concat([df, new_data], ignore_index=True)\n",
        "\n",
        "    df[[\"path\"]] = df[[\"path\"]].astype(str)\n",
        "    df[[\"label\"]] = df[[\"label\"]].astype(str)\n",
        "    df[[\"class_id\"]] = df[[\"class_id\"]].astype(int)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKDBPls8tKnH"
      },
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "train_path = data_path + '/Training/Training/'\n",
        "valid_path = data_path + '/Validation/Validation/'\n",
        "test_path = data_path + '/Testing/Testing/'\n",
        "label_list = ['notsmoking', 'smoking']\n",
        "\n",
        "train_df = create_dataframe(train_path, label_list, 'training')\n",
        "val_df = create_dataframe(valid_path, label_list, 'validation')\n",
        "test_df = create_dataframe(test_path, label_list, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZAgl6untKnH"
      },
      "outputs": [],
      "source": [
        "print(f\"train_data: {len(train_df)}\")\n",
        "print(f\"val_data:{len(val_df)}\")\n",
        "print(f\"test_data:{len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ual7mnVhtKnH"
      },
      "outputs": [],
      "source": [
        "show_imgs = 15\n",
        "idx = np.random.randint(0,len(val_df) , size = show_imgs)\n",
        "fig , axes = plt.subplots(show_imgs // 5 , 5 , figsize = (15 , 10))\n",
        "axes = axes.flatten()\n",
        "for i , ax in enumerate(axes):\n",
        "    full_path = val_df.loc[idx[i]]['path']\n",
        "    ax.imshow(plt.imread(full_path))\n",
        "    ax.set_title(val_df.loc[idx[i]]['label'])\n",
        "    ax.set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "695XC5Y8tKnI"
      },
      "source": [
        "## Dataset & Dataloader\n",
        "\n",
        "Pytorch의 Dataset & Dataloader은, 데이터를 다루고 모델을 훈련 및 시험하기 위하여 가장 주의를 기울여야 될 부분 중의 하나입니다.\n",
        "\n",
        "Dataset은 전체 데이터에서 특정 데이터를 꺼내오는 역할 및 전처리나 augmentation, 추가적인 function 처리를 효율적으로 할 수 있도록 합니다.\n",
        "Dataloader의 경우, Dataset을 Minibatch 형태로 만들어 주며, Batch size나, Shuffle 여부에 대한 것들을 설정할 수 있습니다.\n",
        "\n",
        "자세한 사항은 아래의 링크를 확인해보시기 바랍니다.\n",
        "\n",
        "- https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jYwIXiGtKnI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset , DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYekH15LtKnI"
      },
      "outputs": [],
      "source": [
        "class BaseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self , dataframe , transforms_):\n",
        "        self.df = dataframe\n",
        "        self.transforms_ = transforms_\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self ,index):\n",
        "        img_path = self.df.iloc[index]['path']\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        transformed_img = self.transforms_(img)\n",
        "        class_id = self.df.iloc[index]['class_id']\n",
        "        return transformed_img , class_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxik3wRLtKnI"
      },
      "outputs": [],
      "source": [
        "SimpleTransforms = v2.Compose([\n",
        "    v2.Resize((224,224)), # image 크기 맞추기\n",
        "    v2.PILToTensor(), # torch.tensor로 변환\n",
        "    v2.ToDtype(torch.float32),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),]) # dtype 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-c5I8j7tKnI"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "example_dataset = BaseDataset(train_df , SimpleTransforms) # train_transforms\n",
        "example_loader = DataLoader(example_dataset , batch_size=BATCH_SIZE , shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fzBcF2xtKnI"
      },
      "outputs": [],
      "source": [
        "img, class_id = next(iter(example_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnNimxmbtKnI"
      },
      "outputs": [],
      "source": [
        "img.shape # (batch, channel, W, H)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El7HOUkwtKnJ"
      },
      "outputs": [],
      "source": [
        "img, class_id = next(iter(example_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP_dlAjwtKnJ"
      },
      "outputs": [],
      "source": [
        "# augmentation 참고\n",
        "# https://pytorch.org/vision/main/transforms.html\n",
        "\n",
        "rotation_transform = v2.RandomRotation(degrees=90) # compose에 추가 가능\n",
        "image = Image.open(full_path)\n",
        "rotated_image = rotation_transform(image)\n",
        "rotated_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxzh8jNb1xhr"
      },
      "source": [
        "# 문제 2\n",
        "\n",
        " 1-1의 모델을 **layer를 추가하지 않고**, 아래의 조건을 토대로 성능을\n",
        " 향상시켜보세요.\n",
        "\n",
        "\n",
        " - batch norm, dropout 둘 다 적용\n",
        " - data augmentation 기법 1가지 이상 추가\n",
        " - layer 자체를 추가하는 것 이외의 다른 방법들 추가 적용 가능\n",
        "    - kernel size 등등\n",
        "    - max pooling은 layer로 취급하지 않음\n",
        "    - 이외 추가적인 hyperparameter 변경 가능\n",
        "    - feature size 당연히, 수정 가능\n",
        " - **test acc (75%) 이상 달성**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cyd8tHqftKnJ"
      },
      "outputs": [],
      "source": [
        "CustomTransforms = v2.Compose([\n",
        "    #===============================#\n",
        "\n",
        "\n",
        "\n",
        "    #===============================#\n",
        "    ]) # dtype 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c31JeOsCyv8y"
      },
      "outputs": [],
      "source": [
        "#get dataloader\n",
        "\n",
        "train_dataset = BaseDataset(train_df , CustomTransforms) # train_transforms\n",
        "val_dataset = BaseDataset(val_df , CustomTransforms)\n",
        "test_dataset = BaseDataset(test_df , CustomTransforms)\n",
        "train_loader = DataLoader(train_dataset , batch_size=BATCH_SIZE , shuffle = True)\n",
        "val_loader = DataLoader(val_dataset , batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset , batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JftqeaGlGvBq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedCNN, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 1)\n",
        "\n",
        "\n",
        "        # Define max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "        #===============================================#\n",
        "\n",
        "\n",
        "\n",
        "        #===============================================#\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #===============================================#\n",
        "\n",
        "\n",
        "\n",
        "        #===============================================#\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8OkWC6NHNSj"
      },
      "outputs": [],
      "source": [
        "ImpModel = ImprovedCNN()\n",
        "ImpModel.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhxIwJ8IIOxI"
      },
      "outputs": [],
      "source": [
        "seed_value = 42\n",
        "set_random_seed(seed_value)\n",
        "\n",
        "EPOCHS = 100\n",
        "logs = {\"train_loss\":[] , \"train_acc\":[] , \"val_loss\":[] , \"val_acc\":[]}\n",
        "\n",
        "if os.path.exists('checkpoints') == False:\n",
        "    os.mkdir('checkpoints')\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# hyperparameter 추가 및 변경 가능 설정해보세요\n",
        "# optimizer, lr_scheduler 변경 가능\n",
        "#==============================#\n",
        "\n",
        "\n",
        "\n",
        "#==============================#\n",
        "\n",
        "patience = 10\n",
        "counter = 0\n",
        "best_loss = np.inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvENTzfmHQL2"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train_acc , train_loss = train(train_loader ,\n",
        "                                   ImpModel ,\n",
        "                                   criterion ,\n",
        "                                   optimizer ,\n",
        "                                   Cosine_lr_scheduler)\n",
        "\n",
        "    val_acc , val_loss = test(val_loader , ImpModel , criterion)\n",
        "    print(f'epoch:{epoch} \\\n",
        "    train_loss = {train_loss:.4f} , train_acc:{train_acc:.4f} \\\n",
        "    val_loss = {val_loss:.4f} , val_acc:{val_acc:.4f} \\\n",
        "    learning rate: {optimizer.param_groups[0][\"lr\"]}')\n",
        "    logs['train_loss'].append(train_loss)\n",
        "    logs['train_acc'].append(train_acc)\n",
        "    logs['val_loss'].append(val_loss)\n",
        "    logs['val_acc'].append(val_acc)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        counter = 0\n",
        "        best_loss = val_loss\n",
        "        torch.save(ImpModel.state_dict() , \"checkpoints/Improved_CNN_best.pth\")\n",
        "    else:\n",
        "        counter+=1\n",
        "    if counter >= patience:\n",
        "        test_acc , val_loss = test(test_loader , ImpModel , criterion)\n",
        "        print(\"Early stop !\")\n",
        "        print(test_acc)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmD9Y9YVmLqn"
      },
      "source": [
        "# 문제 3: Pretrained model\n",
        "사전 학습된 모델(Pretrained model)을 통해 위의 이미지 데이터를  흡연 여부를 판별고자 합니다.\n",
        "\n",
        "이를 위해서 모델을 불러오고, 학습 및 검증하여 최종 성능을 평가하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4APb1mdgVqkB"
      },
      "outputs": [],
      "source": [
        "# pretrained 관련\n",
        "import torch\n",
        "import torchvision.transforms as v2\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0wxK6a-y_BP"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7Aly3ZVkAqT"
      },
      "source": [
        "## 문제 3-1: Pretrained Model (backborn)모델 학습\n",
        "\n",
        "아래의 `resnet18` 예제를 참고하여, `vgg16`의 pretrained model를 불러와 Smoke 탐지를 진행할 수 있도록 layer를 수정하시오.\n",
        "\n",
        "- MyVGG16 Class를 완성하시오.\n",
        "- Vgg16의 CNN layer들은 모두 frozen하시오.\n",
        "- layerv 추가 **가능**, 다양한 기법들을 추가해도 됩니다.\n",
        "- **test acc (75%) 이상 달성**\n",
        "- **(extra) test acc (80%) 이상 달성시 추가 점수(+1): freeze한 layer fine-tuning 가능**\n",
        "\n",
        "\n",
        "- https://pytorch.org/vision/stable/models.html 참고"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpMkCw-8yJB5"
      },
      "outputs": [],
      "source": [
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_UYP1KJymCy"
      },
      "outputs": [],
      "source": [
        "print(resnet18) # 각 레이어의 구성을 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrJxpNAsygYn"
      },
      "outputs": [],
      "source": [
        "Last_layer_hiddensize = resnet18.fc.in_features\n",
        "resnet18.fc = nn.Linear(Last_layer_hiddensize, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU0u9aUAzV3k"
      },
      "outputs": [],
      "source": [
        "vgg16 = models.vgg16(weights=models.VGG16_Weights.DEFAULT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPgo95PjCptN"
      },
      "outputs": [],
      "source": [
        "# nn.Linear(10,10).requires_grad = False # gradiant 끄기\n",
        "# nn.Linear(10,10).requires_grad = True # gradiant 켜기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8LFI4cntKnM"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class MyVGG16(nn.Module):\n",
        "    def __init__(self, pretrained_model):\n",
        "        super(MyVGG16, self).__init__()\n",
        "        self.backbone = pretrained_model\n",
        "\n",
        "        #=============================#\n",
        "\n",
        "\n",
        "\n",
        "        #=============================#\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.sigmoid(self.extra_layer(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RWWFhl9tKnM"
      },
      "outputs": [],
      "source": [
        "myvgg16 = MyVGG16(vgg16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgIYNvCtk7Vl"
      },
      "source": [
        "## 문제 3-2: Fine-tuning\n",
        "\n",
        "- `MyVGG16`를 활용하여 Fine-tuning을 진행하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VwX0KlG2ere"
      },
      "outputs": [],
      "source": [
        "seed_value = 42\n",
        "set_random_seed(seed_value)\n",
        "\n",
        "EPOCHS = 100\n",
        "logs = {\"train_loss\":[] , \"train_acc\":[] , \"val_loss\":[] , \"val_acc\":[]}\n",
        "\n",
        "if os.path.exists('checkpoints') == False:\n",
        "    os.mkdir('checkpoints')\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# hyperparameter 추가 및 변경 가능 설정해보세요\n",
        "# optimizer, lr_scheduler 변경 가능\n",
        "#==============================#\n",
        "\n",
        "\n",
        "\n",
        "#==============================#\n",
        "\n",
        "patience = 10\n",
        "counter = 0\n",
        "best_loss = np.inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR8nifMktKnN"
      },
      "outputs": [],
      "source": [
        "def train(dataloader , model , loss_fn , optimizer , lr_scheduler):\n",
        "    size = 0\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss , epoch_correct = 0 , 0\n",
        "\n",
        "    for i ,(data_ , target_) in enumerate(dataloader):\n",
        "\n",
        "        #===================================================#\n",
        "\n",
        "\n",
        "\n",
        "        #===================================================#\n",
        "\n",
        "    train_acc = epoch_correct/size\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    return train_acc , epoch_loss / num_batches\n",
        "\n",
        "\n",
        "def test(dataloader , model , loss_fn):\n",
        "    size = 0\n",
        "    num_baches = len(dataloader)\n",
        "    epoch_loss , epoch_correct= 0 ,0\n",
        "    with torch.no_grad(): # grad 연산 X\n",
        "        model.eval() # evaluation dropout 연산시\n",
        "        for i, (data_ , target_) in enumerate(dataloader):\n",
        "\n",
        "            #========================================#\n",
        "\n",
        "\n",
        "\n",
        "            #========================================#\n",
        "\n",
        "    test_acc = epoch_correct/size\n",
        "\n",
        "    return test_acc  , epoch_loss / num_baches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZmjNnjBtKnN"
      },
      "outputs": [],
      "source": [
        "vgg16.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOO_LCKzrdjL"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train_acc , train_loss = train(train_loader ,\n",
        "                                   vgg16 ,\n",
        "                                   criterion ,\n",
        "                                   optimizer ,\n",
        "                                   Cosine_lr_scheduler)\n",
        "\n",
        "    val_acc , val_loss = test(val_loader , vgg16 , criterion)\n",
        "    print(f'epoch:{epoch} \\\n",
        "    train_loss = {train_loss:.4f} , train_acc:{train_acc:.4f} \\\n",
        "    val_loss = {val_loss:.4f} , val_acc:{val_acc:.4f} \\\n",
        "    learning rate: {optimizer.param_groups[0][\"lr\"]}')\n",
        "    logs['train_loss'].append(train_loss)\n",
        "    logs['train_acc'].append(train_acc)\n",
        "    logs['val_loss'].append(val_loss)\n",
        "    logs['val_acc'].append(val_acc)\n",
        "\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        counter = 0\n",
        "        best_loss = val_loss\n",
        "        torch.save(ImpModel.state_dict() , \"checkpoints/vgg_16_best.pth\")\n",
        "    else:\n",
        "        counter+=1\n",
        "\n",
        "    if counter >= patience:\n",
        "        test_acc , val_loss = test(test_loader , vgg16 , criterion)\n",
        "        print(\"Early stop !\")\n",
        "        print(test_acc)\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ldu7LEotKnN"
      },
      "source": [
        "# 문제 4: 최종 결과 비교\n",
        "\n",
        "- 각 BEST 모델을 불러오고 성능 비교 (ImprovedCNN best,VGG16 best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O23kDe6KtKnN"
      },
      "outputs": [],
      "source": [
        "model_state_dict = torch.load(\" \")\n",
        "ImpCNN = ImprovedCNN()\n",
        "ImprovedCNN.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncbEhe9EtKnN"
      },
      "outputs": [],
      "source": [
        "model_state_dict = torch.load(\" \")\n",
        "myvgg16 = MyVGG16()\n",
        "myvgg16.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQLQsUT_tKnO"
      },
      "outputs": [],
      "source": [
        "#=================================#\n",
        "\n",
        "imp_test_acc =\n",
        "vgg_test_acc =\n",
        "\n",
        "#=================================#\n",
        "print(f\"ImpCNN {imp_test_acc}\")\n",
        "print(f\"MyVgg16 {vgg_test_acc}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}